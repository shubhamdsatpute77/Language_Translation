{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe32c48",
   "metadata": {},
   "source": [
    "# Machine Learning Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a30fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64    ## BATCH SIZE FOR TRAINING\n",
    "epochs = 100       ## NUMBER OF EPOCHS TO TRAIN FOR\n",
    "latent_dim = 256   ## LATENT DIMENSIONALITY OF THE ENCODING SPACE \n",
    "num_samples = 10000 ## NUMER OF SAMPLES TO TRAIN ON\n",
    "data_path = 'mar.txt'   ## PATH TO THE DATA TEXT FILE ON DISC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7646c619",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ee9aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VECTORIZE THE DATA\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "## OPENING AND READING TEXT FILE\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "for line in lines[: min(num_samples, len(lines)-1)]:\n",
    "    if len(line)>0:\n",
    "        input_text, target_text, _ = line.split('\\t')\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    ## USING \"TAB\" AS A \"START SEQUENCE\" CHARACTER\n",
    "    ## FOR THE TARGETS, AND \"\\n\" AS \"END SEQUENCE\" CHARACTER\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_text = input_text.lower()\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f687ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 {'l', '1', 'p', 'u', 'y', '8', 'q', 'a', 'x', ' ', \"'\", '-', 'k', '?', '!', '9', 'h', 'b', 'w', 'i', ',', 'v', '6', '2', 's', '4', ':', '5', 'n', 'j', '$', '3', 'g', '\"', '7', 'z', '.', 'e', 'm', 'r', '0', 'o', 'd', 't', 'f', 'c'}\n"
     ]
    }
   ],
   "source": [
    "print(len(input_characters),input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27643a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 {'श', '२', 'ी', '\\t', 'ई', ':', 'ा', 'ऊ', 'ँ', 'आ', '३', 'ू', 'झ', 'ख', 'ृ', '६', 'घ', 'ज', 'ऐ', 'द', 'त', 'ऋ', '-', 'औ', 'ट', '़', 'ह', 'ब', 'ळ', 'ं', '$', 'ु', 'ि', 'ए', 'े', '१', 'क', '०', 'ॅ', '८', 'र', 'ध', 'ञ', 'ै', 'फ', '्', 'ः', 'व', 'स', ' ', 'इ', 'ष', '?', 'प', 'ौ', ',', 'म', 'उ', '९', '.', 'य', 'ॉ', 'च', 'ढ', 'ठ', 'भ', 'ल', 'ग', '४', 'छ', 'ओ', '!', '\\n', 'ण', '।', 'ो', '\"', '७', 'ड', 'थ', 'न', '५', 'अ', 'ऑ', '\\u200d'}\n"
     ]
    }
   ],
   "source": [
    "print(len(target_characters),target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65e204d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go.',\n",
       " 'run!',\n",
       " 'run!',\n",
       " 'run!',\n",
       " 'run!',\n",
       " 'who?',\n",
       " 'wow!',\n",
       " 'duck!',\n",
       " 'fire!',\n",
       " 'fire!',\n",
       " 'help!',\n",
       " 'help!',\n",
       " 'jump!',\n",
       " 'jump!',\n",
       " 'jump.',\n",
       " 'jump.',\n",
       " 'stop!',\n",
       " 'stop!',\n",
       " 'wait!',\n",
       " 'wait!',\n",
       " 'hello!',\n",
       " 'hurry!',\n",
       " 'hurry!',\n",
       " 'hurry!',\n",
       " 'i won!',\n",
       " 'i won!',\n",
       " 'get up.',\n",
       " 'got it!',\n",
       " 'got it?',\n",
       " 'got it?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c815a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tजा.\\n',\n",
       " '\\tपळ!\\n',\n",
       " '\\tधाव!\\n',\n",
       " '\\tपळा!\\n',\n",
       " '\\tधावा!\\n',\n",
       " '\\tकोण?\\n',\n",
       " '\\tवाह!\\n',\n",
       " '\\tखाली वाका!\\n',\n",
       " '\\tआग!\\n',\n",
       " '\\tफायर!\\n',\n",
       " '\\tवाचवा!\\n',\n",
       " '\\tवाचव!\\n',\n",
       " '\\tउडी मार!\\n',\n",
       " '\\tउडी मारा!\\n',\n",
       " '\\tउडी मार.\\n',\n",
       " '\\tउडी मारा.\\n',\n",
       " '\\tथांबा!\\n',\n",
       " '\\tथांब!\\n',\n",
       " '\\tथांबा!\\n',\n",
       " '\\tथांब!\\n',\n",
       " '\\tहॅलो!\\n',\n",
       " '\\tलवकर!\\n',\n",
       " '\\tलवकर कर!\\n',\n",
       " '\\tलवकर करा!\\n',\n",
       " '\\tमी जिंकलो!\\n',\n",
       " '\\tमी जिंकले!\\n',\n",
       " '\\tऊठ.\\n',\n",
       " '\\tपकडलं!\\n',\n",
       " '\\tकळलं?\\n',\n",
       " '\\tसमजलं?\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767c8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defeaf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 46\n",
      "Number of unique output tokens: 85\n",
      "Maximum sequence length for inputs: 19\n",
      "Maximum sequence length for outputs: 42\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:',len(input_texts))\n",
    "print('Number of unique input tokens:',num_encoder_tokens)\n",
    "print('Number of unique output tokens:',num_decoder_tokens)\n",
    "print('Maximum sequence length for inputs:',max_encoder_seq_length)\n",
    "print('Maximum sequence length for outputs:',max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4359c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(char,i) for i,char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char,i) for i,char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "694de45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '$': 3,\n",
       " \"'\": 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " '0': 8,\n",
       " '1': 9,\n",
       " '2': 10,\n",
       " '3': 11,\n",
       " '4': 12,\n",
       " '5': 13,\n",
       " '6': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " '?': 19,\n",
       " 'a': 20,\n",
       " 'b': 21,\n",
       " 'c': 22,\n",
       " 'd': 23,\n",
       " 'e': 24,\n",
       " 'f': 25,\n",
       " 'g': 26,\n",
       " 'h': 27,\n",
       " 'i': 28,\n",
       " 'j': 29,\n",
       " 'k': 30,\n",
       " 'l': 31,\n",
       " 'm': 32,\n",
       " 'n': 33,\n",
       " 'o': 34,\n",
       " 'p': 35,\n",
       " 'q': 36,\n",
       " 'r': 37,\n",
       " 's': 38,\n",
       " 't': 39,\n",
       " 'u': 40,\n",
       " 'v': 41,\n",
       " 'w': 42,\n",
       " 'x': 43,\n",
       " 'y': 44,\n",
       " 'z': 45}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1882b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '\"': 4,\n",
       " '$': 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " '?': 10,\n",
       " 'ँ': 11,\n",
       " 'ं': 12,\n",
       " 'ः': 13,\n",
       " 'अ': 14,\n",
       " 'आ': 15,\n",
       " 'इ': 16,\n",
       " 'ई': 17,\n",
       " 'उ': 18,\n",
       " 'ऊ': 19,\n",
       " 'ऋ': 20,\n",
       " 'ए': 21,\n",
       " 'ऐ': 22,\n",
       " 'ऑ': 23,\n",
       " 'ओ': 24,\n",
       " 'औ': 25,\n",
       " 'क': 26,\n",
       " 'ख': 27,\n",
       " 'ग': 28,\n",
       " 'घ': 29,\n",
       " 'च': 30,\n",
       " 'छ': 31,\n",
       " 'ज': 32,\n",
       " 'झ': 33,\n",
       " 'ञ': 34,\n",
       " 'ट': 35,\n",
       " 'ठ': 36,\n",
       " 'ड': 37,\n",
       " 'ढ': 38,\n",
       " 'ण': 39,\n",
       " 'त': 40,\n",
       " 'थ': 41,\n",
       " 'द': 42,\n",
       " 'ध': 43,\n",
       " 'न': 44,\n",
       " 'प': 45,\n",
       " 'फ': 46,\n",
       " 'ब': 47,\n",
       " 'भ': 48,\n",
       " 'म': 49,\n",
       " 'य': 50,\n",
       " 'र': 51,\n",
       " 'ल': 52,\n",
       " 'ळ': 53,\n",
       " 'व': 54,\n",
       " 'श': 55,\n",
       " 'ष': 56,\n",
       " 'स': 57,\n",
       " 'ह': 58,\n",
       " '़': 59,\n",
       " 'ा': 60,\n",
       " 'ि': 61,\n",
       " 'ी': 62,\n",
       " 'ु': 63,\n",
       " 'ू': 64,\n",
       " 'ृ': 65,\n",
       " 'ॅ': 66,\n",
       " 'े': 67,\n",
       " 'ै': 68,\n",
       " 'ॉ': 69,\n",
       " 'ो': 70,\n",
       " 'ौ': 71,\n",
       " '्': 72,\n",
       " '।': 73,\n",
       " '०': 74,\n",
       " '१': 75,\n",
       " '२': 76,\n",
       " '३': 77,\n",
       " '४': 78,\n",
       " '५': 79,\n",
       " '६': 80,\n",
       " '७': 81,\n",
       " '८': 82,\n",
       " '९': 83,\n",
       " '\\u200d': 84}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd47b30",
   "metadata": {},
   "source": [
    "### One Hot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00770265",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3670dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        ## decoder_target_data IS AHEAD OF decoder_input_data BY ONE TIMESTEP\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            ## decoder_target_data WILL BE AHEAD BY ONE TIMESTEP\n",
    "            ## AND WILL NOT INCLUDE THE START CHARACTER\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36e72b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 46)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e572070",
   "metadata": {},
   "source": [
    "## Sequence to Sequence Model with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be63f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE AN INPUT SEQUENCE AND PROCESS IT\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "## WE DISCARD \"encoder_outputs\" AND ONLY KEEP STATES\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14a06edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET UP THE DECODER USING 'encoder_states' AS INITIAL STATE\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "## WE SETUP OUR DECODER TO RETURN FULL OUTPUT SEQUENCES\n",
    "## AND TO RETURN INTERNAL STATES AS WELL. WE DON'T USE THE \n",
    "## RETURN STATES IN THE TRAINING MODEL, BUT WE WILL USE THEM IN INFERENCE\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead76c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 31s 251ms/step - loss: 1.5422 - accuracy: 0.6424 - val_loss: 1.5863 - val_accuracy: 0.5936\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 1.1430 - accuracy: 0.7109 - val_loss: 1.2024 - val_accuracy: 0.6915\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.9225 - accuracy: 0.7586 - val_loss: 1.0559 - val_accuracy: 0.7169\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.8231 - accuracy: 0.7784 - val_loss: 0.9788 - val_accuracy: 0.7320\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 29s 230ms/step - loss: 0.7608 - accuracy: 0.7906 - val_loss: 0.9273 - val_accuracy: 0.7463\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.7087 - accuracy: 0.8036 - val_loss: 0.8848 - val_accuracy: 0.7542\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.6645 - accuracy: 0.8158 - val_loss: 0.8664 - val_accuracy: 0.7603\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.6287 - accuracy: 0.8252 - val_loss: 0.8247 - val_accuracy: 0.7739\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 31s 245ms/step - loss: 0.5960 - accuracy: 0.8342 - val_loss: 0.8007 - val_accuracy: 0.7785\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 29s 234ms/step - loss: 0.5674 - accuracy: 0.8418 - val_loss: 0.7661 - val_accuracy: 0.7901\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 29s 232ms/step - loss: 0.5416 - accuracy: 0.8487 - val_loss: 0.7578 - val_accuracy: 0.7924\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.5184 - accuracy: 0.8545 - val_loss: 0.7406 - val_accuracy: 0.7954\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.4968 - accuracy: 0.8603 - val_loss: 0.7416 - val_accuracy: 0.7967\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.4763 - accuracy: 0.8659 - val_loss: 0.7209 - val_accuracy: 0.8025\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.4571 - accuracy: 0.8709 - val_loss: 0.7071 - val_accuracy: 0.8073\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 29s 230ms/step - loss: 0.4397 - accuracy: 0.8756 - val_loss: 0.7005 - val_accuracy: 0.8095\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 29s 233ms/step - loss: 0.4225 - accuracy: 0.8802 - val_loss: 0.7062 - val_accuracy: 0.8090\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.4061 - accuracy: 0.8844 - val_loss: 0.6941 - val_accuracy: 0.8130\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 30s 242ms/step - loss: 0.3908 - accuracy: 0.8886 - val_loss: 0.7029 - val_accuracy: 0.8115\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 29s 233ms/step - loss: 0.3762 - accuracy: 0.8927 - val_loss: 0.6955 - val_accuracy: 0.8139\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 29s 232ms/step - loss: 0.3619 - accuracy: 0.8965 - val_loss: 0.6949 - val_accuracy: 0.8143\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.3484 - accuracy: 0.8998 - val_loss: 0.6972 - val_accuracy: 0.8161\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.3353 - accuracy: 0.9037 - val_loss: 0.6993 - val_accuracy: 0.8162\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.3233 - accuracy: 0.9070 - val_loss: 0.7118 - val_accuracy: 0.8148\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.3107 - accuracy: 0.9111 - val_loss: 0.7160 - val_accuracy: 0.8153\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.2998 - accuracy: 0.9134 - val_loss: 0.7128 - val_accuracy: 0.8162\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.2883 - accuracy: 0.9169 - val_loss: 0.7161 - val_accuracy: 0.8159\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.2775 - accuracy: 0.9194 - val_loss: 0.7278 - val_accuracy: 0.8155\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.2678 - accuracy: 0.9225 - val_loss: 0.7315 - val_accuracy: 0.8158\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.2578 - accuracy: 0.9253 - val_loss: 0.7389 - val_accuracy: 0.8155\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.2482 - accuracy: 0.9281 - val_loss: 0.7531 - val_accuracy: 0.8157\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 28s 228ms/step - loss: 0.2393 - accuracy: 0.9303 - val_loss: 0.7583 - val_accuracy: 0.8154\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.2301 - accuracy: 0.9330 - val_loss: 0.7663 - val_accuracy: 0.8165\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.2223 - accuracy: 0.9350 - val_loss: 0.7728 - val_accuracy: 0.8164\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 29s 231ms/step - loss: 0.2138 - accuracy: 0.9378 - val_loss: 0.7801 - val_accuracy: 0.8147\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 29s 236ms/step - loss: 0.2064 - accuracy: 0.9393 - val_loss: 0.7920 - val_accuracy: 0.8141\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.1992 - accuracy: 0.9417 - val_loss: 0.7976 - val_accuracy: 0.8152\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.1923 - accuracy: 0.9432 - val_loss: 0.8128 - val_accuracy: 0.8149\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.1856 - accuracy: 0.9454 - val_loss: 0.8210 - val_accuracy: 0.8141\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.1782 - accuracy: 0.9476 - val_loss: 0.8270 - val_accuracy: 0.8131\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.1720 - accuracy: 0.9493 - val_loss: 0.8407 - val_accuracy: 0.8145\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.1664 - accuracy: 0.9508 - val_loss: 0.8414 - val_accuracy: 0.8128\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 28s 227ms/step - loss: 0.1603 - accuracy: 0.9527 - val_loss: 0.8592 - val_accuracy: 0.8119\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 28s 228ms/step - loss: 0.1548 - accuracy: 0.9539 - val_loss: 0.8627 - val_accuracy: 0.8141\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.1495 - accuracy: 0.9557 - val_loss: 0.8758 - val_accuracy: 0.8121\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.1443 - accuracy: 0.9565 - val_loss: 0.8869 - val_accuracy: 0.8117\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.1395 - accuracy: 0.9582 - val_loss: 0.9010 - val_accuracy: 0.8113\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 29s 234ms/step - loss: 0.1348 - accuracy: 0.9593 - val_loss: 0.9020 - val_accuracy: 0.8115\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 29s 234ms/step - loss: 0.1306 - accuracy: 0.9606 - val_loss: 0.9131 - val_accuracy: 0.8098\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.1261 - accuracy: 0.9617 - val_loss: 0.9236 - val_accuracy: 0.8110\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 35s 283ms/step - loss: 0.1218 - accuracy: 0.9627 - val_loss: 0.9320 - val_accuracy: 0.8092\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.1178 - accuracy: 0.9636 - val_loss: 0.9422 - val_accuracy: 0.8108\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 28s 225ms/step - loss: 0.1146 - accuracy: 0.9646 - val_loss: 0.9525 - val_accuracy: 0.8093\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 29s 234ms/step - loss: 0.1106 - accuracy: 0.9660 - val_loss: 0.9641 - val_accuracy: 0.8089\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 31s 249ms/step - loss: 0.1072 - accuracy: 0.9670 - val_loss: 0.9730 - val_accuracy: 0.8078\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 30s 242ms/step - loss: 0.1036 - accuracy: 0.9681 - val_loss: 0.9789 - val_accuracy: 0.8095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.1007 - accuracy: 0.9686 - val_loss: 0.9901 - val_accuracy: 0.8087\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 32s 255ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 1.0037 - val_accuracy: 0.8079\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 31s 250ms/step - loss: 0.0949 - accuracy: 0.9700 - val_loss: 1.0018 - val_accuracy: 0.8086\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 29s 235ms/step - loss: 0.0919 - accuracy: 0.9711 - val_loss: 1.0120 - val_accuracy: 0.8075\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.0894 - accuracy: 0.9716 - val_loss: 1.0184 - val_accuracy: 0.8094\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 31s 249ms/step - loss: 0.0871 - accuracy: 0.9723 - val_loss: 1.0252 - val_accuracy: 0.8075\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 31s 250ms/step - loss: 0.0847 - accuracy: 0.9729 - val_loss: 1.0444 - val_accuracy: 0.8089\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 30s 241ms/step - loss: 0.0823 - accuracy: 0.9738 - val_loss: 1.0436 - val_accuracy: 0.8067\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.0802 - accuracy: 0.9740 - val_loss: 1.0508 - val_accuracy: 0.8085\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 33s 264ms/step - loss: 0.0778 - accuracy: 0.9749 - val_loss: 1.0549 - val_accuracy: 0.8063\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.0758 - accuracy: 0.9755 - val_loss: 1.0689 - val_accuracy: 0.8071\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.0743 - accuracy: 0.9757 - val_loss: 1.0714 - val_accuracy: 0.8075\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 31s 249ms/step - loss: 0.0721 - accuracy: 0.9764 - val_loss: 1.0705 - val_accuracy: 0.8085\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.0705 - accuracy: 0.9767 - val_loss: 1.0857 - val_accuracy: 0.8078\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.0689 - accuracy: 0.9773 - val_loss: 1.0806 - val_accuracy: 0.8081\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.0671 - accuracy: 0.9778 - val_loss: 1.1003 - val_accuracy: 0.8065\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.0661 - accuracy: 0.9777 - val_loss: 1.0937 - val_accuracy: 0.8073\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.0640 - accuracy: 0.9785 - val_loss: 1.1041 - val_accuracy: 0.8085\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 31s 252ms/step - loss: 0.0628 - accuracy: 0.9788 - val_loss: 1.1199 - val_accuracy: 0.8082\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.0617 - accuracy: 0.9789 - val_loss: 1.1111 - val_accuracy: 0.8081\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 31s 244ms/step - loss: 0.0602 - accuracy: 0.9793 - val_loss: 1.1246 - val_accuracy: 0.8057\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.0588 - accuracy: 0.9797 - val_loss: 1.1306 - val_accuracy: 0.8083\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.0576 - accuracy: 0.9801 - val_loss: 1.1351 - val_accuracy: 0.8078\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 1.1433 - val_accuracy: 0.8061\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.0556 - accuracy: 0.9805 - val_loss: 1.1439 - val_accuracy: 0.8067\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.0549 - accuracy: 0.9805 - val_loss: 1.1516 - val_accuracy: 0.8072\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 32s 252ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 1.1516 - val_accuracy: 0.8068\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 30s 242ms/step - loss: 0.0528 - accuracy: 0.9812 - val_loss: 1.1585 - val_accuracy: 0.8069\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 30s 239ms/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 1.1699 - val_accuracy: 0.8062\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 31s 247ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 1.1640 - val_accuracy: 0.8078\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 31s 244ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 1.1698 - val_accuracy: 0.8065\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 30s 243ms/step - loss: 0.0501 - accuracy: 0.9817 - val_loss: 1.1789 - val_accuracy: 0.8068\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 30s 240ms/step - loss: 0.0489 - accuracy: 0.9822 - val_loss: 1.1754 - val_accuracy: 0.8077\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 31s 252ms/step - loss: 0.0485 - accuracy: 0.9821 - val_loss: 1.1704 - val_accuracy: 0.8082\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.0477 - accuracy: 0.9822 - val_loss: 1.1943 - val_accuracy: 0.8063\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 30s 242ms/step - loss: 0.0472 - accuracy: 0.9824 - val_loss: 1.1858 - val_accuracy: 0.8068\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 31s 245ms/step - loss: 0.0465 - accuracy: 0.9827 - val_loss: 1.2014 - val_accuracy: 0.8080\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 31s 248ms/step - loss: 0.0459 - accuracy: 0.9829 - val_loss: 1.1871 - val_accuracy: 0.8078\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 33s 261ms/step - loss: 0.0457 - accuracy: 0.9828 - val_loss: 1.2093 - val_accuracy: 0.8074\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 30s 238ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 1.1983 - val_accuracy: 0.8078\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.0447 - accuracy: 0.9831 - val_loss: 1.2063 - val_accuracy: 0.8071\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.0436 - accuracy: 0.9832 - val_loss: 1.2101 - val_accuracy: 0.8078\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 30s 241ms/step - loss: 0.0432 - accuracy: 0.9834 - val_loss: 1.2120 - val_accuracy: 0.8064\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.0430 - accuracy: 0.9834 - val_loss: 1.2157 - val_accuracy: 0.8086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2996b09f7c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DEFINE THE MODEL THAT WILL TURN 'encoder_input_data' INTO 'decoder_target_data'\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "\n",
    "## TRAINING\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3b28d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: that's old news.\n",
      "Decoded sentence: ती जुनी बातमी आहे.\n",
      "\n",
      "-\n",
      "Input sentence: that's old news.\n",
      "Decoded sentence: ती जुनी बातमी आहे.\n",
      "\n",
      "-\n",
      "Input sentence: that's the news.\n",
      "Decoded sentence: तीच बातमी आहे.\n",
      "\n",
      "-\n",
      "Input sentence: that's your job.\n",
      "Decoded sentence: ते तुमचं काम आहे.\n",
      "\n",
      "-\n",
      "Input sentence: that's your job.\n",
      "Decoded sentence: ते तुमचं काम आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the bus is full.\n",
      "Decoded sentence: बस भरली आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the cat escaped.\n",
      "Decoded sentence: मांजर सुटून पळाली.\n",
      "\n",
      "-\n",
      "Input sentence: the cat is lazy.\n",
      "Decoded sentence: मांजर आळशी आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the cup is full.\n",
      "Decoded sentence: कप भरलं आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the dog is dead.\n",
      "Decoded sentence: कुत्रा मेला आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the dog is mine.\n",
      "Decoded sentence: कुत्रा माझा आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the dog is ours.\n",
      "Decoded sentence: कुत्रा आमचा आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the dog is ours.\n",
      "Decoded sentence: कुत्रा आमचा आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the door opened.\n",
      "Decoded sentence: दरवाजा उघडला.\n",
      "\n",
      "-\n",
      "Input sentence: the lake is big.\n",
      "Decoded sentence: तलाव मोठा आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the leaves fell.\n",
      "Decoded sentence: ती पानं पडली.\n",
      "\n",
      "-\n",
      "Input sentence: the leaves fell.\n",
      "Decoded sentence: ती पानं पडली.\n",
      "\n",
      "-\n",
      "Input sentence: the light is on.\n",
      "Decoded sentence: दिवा चालू आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the light is on.\n",
      "Decoded sentence: दिवा चालू आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the mouse moved.\n",
      "Decoded sentence: उंदीर हलला.\n",
      "\n",
      "-\n",
      "Input sentence: the mouse moved.\n",
      "Decoded sentence: उंदीर हलला.\n",
      "\n",
      "-\n",
      "Input sentence: the net is huge.\n",
      "Decoded sentence: जाळ प्रचंड आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the pay is good.\n",
      "Decoded sentence: पगार चांगला आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the radar broke.\n",
      "Decoded sentence: रडार बिघडला.\n",
      "\n",
      "-\n",
      "Input sentence: the room is hot.\n",
      "Decoded sentence: ही खोली गरम आहे.\n",
      "\n",
      "-\n",
      "Input sentence: the sea is blue.\n",
      "Decoded sentence: समुद्र निळा असतो.\n",
      "\n",
      "-\n",
      "Input sentence: the sea is blue.\n",
      "Decoded sentence: समुद्र निळा असतो.\n",
      "\n",
      "-\n",
      "Input sentence: the soldier ran.\n",
      "Decoded sentence: सैनिक पळाला.\n",
      "\n",
      "-\n",
      "Input sentence: the soldier ran.\n",
      "Decoded sentence: सैनिक पळाला.\n",
      "\n",
      "-\n",
      "Input sentence: the sun has set.\n",
      "Decoded sentence: सूर्य मावळला आहे.\n",
      "\n",
      "-\n",
      "Input sentence: there was blood.\n",
      "Decoded sentence: रक्त होतं.\n",
      "\n",
      "-\n",
      "Input sentence: there's no cure.\n",
      "Decoded sentence: उपाय नाहीये.\n",
      "\n",
      "-\n",
      "Input sentence: there's no salt.\n",
      "Decoded sentence: मीठ नाहीये.\n",
      "\n",
      "-\n",
      "Input sentence: these are fresh.\n",
      "Decoded sentence: हे ताजे आहेत.\n",
      "\n",
      "-\n",
      "Input sentence: these are fresh.\n",
      "Decoded sentence: हे ताजे आहेत.\n",
      "\n",
      "-\n",
      "Input sentence: these are fresh.\n",
      "Decoded sentence: हे ताजे आहेत.\n",
      "\n",
      "-\n",
      "Input sentence: they all talked.\n",
      "Decoded sentence: ते सर्व बोलले.\n",
      "\n",
      "-\n",
      "Input sentence: they are actors.\n",
      "Decoded sentence: त्या अभिनेत्या आहेत.\n",
      "\n",
      "-\n",
      "Input sentence: they are actors.\n",
      "Decoded sentence: त्या अभिनेत्या आहेत.\n",
      "\n",
      "-\n",
      "Input sentence: they caught tom.\n",
      "Decoded sentence: त्यांनी टॉमला पकडलं.\n",
      "\n",
      "-\n",
      "Input sentence: they found this.\n",
      "Decoded sentence: त्यांना हे सापडलं.\n",
      "\n",
      "-\n",
      "Input sentence: they hate women.\n",
      "Decoded sentence: ते स्त्रियांचा तिरस्कार करतात.\n",
      "\n",
      "-\n",
      "Input sentence: they helped tom.\n",
      "Decoded sentence: त्यांनी टॉमची मदत केली.\n",
      "\n",
      "-\n",
      "Input sentence: they live there.\n",
      "Decoded sentence: त्या तिथे राहतात.\n",
      "\n",
      "-\n",
      "Input sentence: they live there.\n",
      "Decoded sentence: त्या तिथे राहतात.\n",
      "\n",
      "-\n",
      "Input sentence: they look bored.\n",
      "Decoded sentence: ते कंटाळलेले दिसताहेत.\n",
      "\n",
      "-\n",
      "Input sentence: they understood.\n",
      "Decoded sentence: त्या समजल्या.\n",
      "\n",
      "-\n",
      "Input sentence: they understood.\n",
      "Decoded sentence: त्या समजल्या.\n",
      "\n",
      "-\n",
      "Input sentence: they were angry.\n",
      "Decoded sentence: त्या रागावलेल्या होत्या.\n",
      "\n",
      "-\n",
      "Input sentence: they were angry.\n",
      "Decoded sentence: त्या रागावलेल्या होत्या.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## NEXT: INFERENCE MODE (SAMPLING)\n",
    "## HERE'S THE DRILL:\n",
    "## 1. ENCODE INPUT AND RETRIEVE INITIAL DECODER STATE.\n",
    "## 2. RUN ONE STEP OF DECODER WITH THIS INITIAL STATE\n",
    "## AND A 'START OF SEQUENCE' TOKEN AS TARGET.\n",
    "## 3. REPEAT WITH CURRENT TARGET TOKEN AND CURRENT STATES \n",
    "\n",
    "## DEFINE SAMPLING MODEL\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "## REVERSE-LOOKUP TOKEN INDEX TO DECODE SEQUENCES BACK TO SOMETHING READABLE \n",
    "reverse_input_char_index = dict((i,char) for char,i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i,char) for char,i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    ## ENCODE THE INPUT AS STATE VECTORS\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    ## GENERATE EMPTY TARGET SEQUENCE OF LENGTH 1:\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    ## POPULATE THE FIRST CHARACTER OF TARGET SEQUENCE WITH THE START CHARACTER.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "    \n",
    "    ## SAMPLING LOOP FOR BATCH OF SEQUENCES\n",
    "    ## (TO SIMPLIFY, HERE WE ASSUME A BATCH OF SIZE 1)\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        ## SAMPLE TO TOKEN\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        ## EXIT CONDITION: EITHER HIT MAX LENGTH\n",
    "        ## OR FIND STOP CHARACTER.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "            \n",
    "        ## UPDATE THE TARGET SEQUENCE (OF LENGTH 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        \n",
    "        ## UPDATE STATES\n",
    "        states_value = [h, c]\n",
    "        \n",
    "    return decoded_sentence\n",
    "    \n",
    "for seq_index in range(5000,5050):\n",
    "    ## TAKE ONE SENTENCE (PART OF TRAINING SET)\n",
    "    ## FOR TRYING OUT DECODING.\n",
    "    \n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d0000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
